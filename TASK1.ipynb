{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4f7280-d323-4923-b498-5bef6c83ae0f",
      "metadata": {
        "id": "6c4f7280-d323-4923-b498-5bef6c83ae0f"
      },
      "outputs": [],
      "source": [
        "# TEXT-TO-IMAGE PIPELINE (GAN + TEXT EMBEDDINGS)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55231770-7a31-46ef-9aae-200914947185",
      "metadata": {
        "id": "55231770-7a31-46ef-9aae-200914947185"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "from transformers import CLIPTokenizer, CLIPTextModel\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re, os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24e2f1e-3d50-4dba-8530-fe32f40b9f6d",
      "metadata": {
        "id": "f24e2f1e-3d50-4dba-8530-fe32f40b9f6d"
      },
      "outputs": [],
      "source": [
        "#TEXT PREPROCESSOR\n",
        "class TextPreprocessor:\n",
        "  def __init__(self, lowercase= True, remove_punct=True):\n",
        "    self.lowercase = lowercase\n",
        "    self.remove_punct = remove_punct\n",
        "\n",
        "  def clean(self, text: str) -> str:\n",
        "      text = text.strip()\n",
        "      if self.lowercase:\n",
        "          text = text.lower()\n",
        "      if self.remove_punct:\n",
        "          text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "      return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8590278f-db68-4a6c-9826-717f52725b04",
      "metadata": {
        "id": "8590278f-db68-4a6c-9826-717f52725b04"
      },
      "outputs": [],
      "source": [
        "#TEXT EMBEDDER\n",
        "class TextEmbedder:\n",
        "    \"\"\"Uses CLIP text encoder to produce semantic embeddings.\"\"\"\n",
        "    def __init__(self, model_name=\"openai/clip-vit-base-patch32\", device=\"auto\"):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and device != \"cpu\" else \"cpu\")\n",
        "        self.tokenizer = CLIPTokenizer.from_pretrained(model_name)\n",
        "        self.text_encoder = CLIPTextModel.from_pretrained(model_name).to(self.device)\n",
        "        self.text_encoder.eval()\n",
        "    @torch.no_grad()\n",
        "    def encode(self, text: str) -> torch.Tensor:\n",
        "      inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "      outputs = self.text_encoder(**{k: v.to(self.device) for k, v in inputs.items()})\n",
        "      return outputs.last_hidden_state.mean(dim=1)  # sentence embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CONDITIONAL GAN\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"A simple conditional generator using embeddings.\"\"\"\n",
        "    def __init__(self, embedding_dim=512, noise_dim=100, img_size=64):\n",
        "        super().__init__()\n",
        "        self.input_dim = embedding_dim + noise_dim\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256 * 8 * 8),\n",
        "            nn.BatchNorm1d(256 * 8 * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.Unflatten(1, (256, 8, 8)),\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, embedding):\n",
        "        x = torch.cat((z, embedding), dim=1)\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "tJAM-LLV6cCi"
      },
      "id": "tJAM-LLV6cCi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Conditional discriminator.\"\"\"\n",
        "    def __init__(self, embedding_dim=512, img_size=64):\n",
        "        super().__init__()\n",
        "        self.img_encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, stride=2, padding=1), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.fc = nn.Linear(256 * 8 * 8 + embedding_dim, 1)\n",
        "\n",
        "    def forward(self, img, embedding):\n",
        "        img_feat = self.img_encoder(img)\n",
        "        x = torch.cat((img_feat, embedding), dim=1)\n",
        "        return torch.sigmoid(self.fc(x))"
      ],
      "metadata": {
        "id": "trA3IG8w6E4j"
      },
      "id": "trA3IG8w6E4j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEXT TO IMAGE PIPELINE\n",
        "class TextToImagePipeline:\n",
        "    \"\"\"Combines text preprocessing, embedding, and GAN generation.\"\"\"\n",
        "    def __init__(self, device=\"auto\"):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and device != \"cpu\" else \"cpu\")\n",
        "        self.preprocessor = TextPreprocessor()\n",
        "        self.embedder = TextEmbedder(device=str(self.device))\n",
        "        self.generator = Generator().to(self.device)\n",
        "        self.generator.eval()\n",
        "\n",
        "    def generate(self, text: str, seed: int = None, noise_dim: int = 100) -> Image.Image:\n",
        "        torch.manual_seed(seed or np.random.randint(0, 999999))\n",
        "        cleaned = self.preprocessor.clean(text)\n",
        "        embedding = self.embedder.encode(cleaned)\n",
        "        noise = torch.randn(1, noise_dim, device=self.device)\n",
        "        fake_img = self.generator(noise, embedding)\n",
        "        return self._to_image(fake_img)\n",
        "\n",
        "    def _to_image(self, tensor):\n",
        "        img = (tensor.squeeze(0).detach().cpu() + 1) / 2  # scale to [0,1]\n",
        "        img = T.ToPILImage()(img)\n",
        "        return img"
      ],
      "metadata": {
        "id": "W_I_bWJw6E66"
      },
      "id": "W_I_bWJw6E66",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SIMULATION\n",
        "if __name__ == \"__main__\":\n",
        "    pipe = TextToImagePipeline()\n",
        "\n",
        "    prompt = \"Rose\"\n",
        "    print(f\"Generating image for: '{prompt}'\")\n",
        "\n",
        "    img = pipe.generate(prompt, seed=42)\n",
        "    img.show()\n",
        "\n",
        "    # For display in a notebook:\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(prompt)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "DsSsGkQC6E-T",
        "outputId": "b4fc4787-5fd6-4a55-95a9-5581d76f882d"
      },
      "id": "DsSsGkQC6E-T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating image for: 'Rose'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52eb9a6b-bbc4-422a-a0aa-1c104f2d693d",
      "metadata": {
        "id": "52eb9a6b-bbc4-422a-a0aa-1c104f2d693d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}